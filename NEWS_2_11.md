2019-02-11
----------

### What did you do this week?

- Rachel: Our team met Sophie at ProPublica through Zoom. We discussed the scope of the project which was fairly straight forward and discussed the expected turn around time of the project which is 2 weeks to a month from now. Last week, we figured out how to manually scrape the data and noticed the exceptions in the formatting that we have to note. As a group, we decided to focus on using R instead of Python for this scraping project since Ru found Selenium that functions in R. This week, I have worked on understanding the basics of Selenium as well as following through with the manual scraping data method we were exploring last week in order to practice using rvest and other r scraping packages.

- Ru: We talked to Sophie, our new contact for this project last week Wednesday to go over the project and hear her expectations for the project. I also looked at various web scraping packages in R, including rvest, xml2, httr and RSelenium in order to find out which may be better suited for our project. Sophie had suggested using Selenium in R, but I found that R has its own version(RSelenium) so I have been learning how to use it. I  managed to install Docker in order to virtually interact with the webpage and have been playing around with        Docker and RSelenium to have a feel of this package. At the moment, I have been using other tutorials online instead of Datacamp as it seems Datacamp may not have enough information for what we need.  

- Maggie: Worked on a method of web scraping that could work with the
    task on hand, but was problematic because it was largely manual.
    Talked to our contact at ProPublica and determined what our goals
    were with her and what her expectations were of us. Worked on a
    datacamp course regarding webscraping, which we believe will be our
    main task after talking to our contact. Particularly, I worked on
    trying to understand Selenium for R, because that was suggested to
    us by our contact, and tried to determine if this would work with
    our project.

### What is it that you're struggling with right now?

- Rachel: I am struggling the most with gaining enough knowledge and skill to deliver this project in the suggested time frame. Since we are so new to all these tools, its really hard to get basic footing to even build a basic algorithm. It's also really difficult because it feels like the group is running in circles because we don't know where to start so a lot of false starts seem to keep occuring. Also, (this is entirely my personal preference which should be discussed with the group) I would like to meet with the team more times during the week because I feel like I learn the most with group work and having other people in live time to help me through a problem or logic that I am struggling with. However, our schedules are generally conflicting so we will need to sort this discrepancy out.

- Ru: Getting started. I understand our webpage is interactive, and has no endpoint url. Though I now know how to navigate it using RSelenium, I haven't quite found the best way to find the elements in page using CSS selectors. I think this may be because we have a lot of classes within a div? and divs within divs? I feel this may be easier to understand once I understand selection of different elements so I'm still looking for tutorials on this.  

- Maggie: Right now, I am trying to determine a better way of web
    scraping the website containing the names of doctors that works with
    the formatting of the website, because our current method is based
    mostly around the manual collection and input of data.

### What are you planning to do next week?

- Rachel: Learn as much as we can about the tools that can potentially help us to solving how to get around the static url and automating the scraping process. I think that we need to devise a strategy to solve this problem one way before we keep searching for new avenues to solve the problem.

- Ru: I'm planning to learning more about css selection in RSelenium and find out if I can pull out a few doctor's names and their addresses from the website using RSelenium and possibly rvest.  

- Maggie: Do more research on Selenium and start working with it or a
    similar program to try to scrape the website for relevant data for
    our client.
