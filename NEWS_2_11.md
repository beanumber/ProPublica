2019-02-11
----------

### What did you do this week?

-   Rachel:

-   Ru: We talked to Sophie, our new contact for this project last week Wednesday to go over the project and hear      her expectations for the project. I also looked at various web scraping packages in R, including rvest, xml2,      httr and RSelenium in order to find out which may be better suited for our project. Sophie had suggested using     Selenium in R, but I found that R has its own version(RSelenium) so I have been learning how to use it. I          managed to install Docker in order to virtually interact with the webpage and have been playing around with        Docker and RSelenium to have a feel of this package. At the moment, I have been using other tutorials online       instead of Datacamp as it seems Datacamp may not have enough information for what we need.  

-   Maggie: Worked on a method of web scraping that could work with the
    task on hand, but was problematic because it was largely manual.
    Talked to our contact at ProPublica and determined what our goals
    were with her and what her expectations were of us. Worked on a
    datacamp course regarding webscraping, which we believe will be our
    main task after talking to our contact. Particularly, I worked on
    trying to understand Selenium for R, because that was suggested to
    us by our contact, and tried to determine if this would work with
    our project.

### What is it that you're struggling with right now?

-   Rachel:

-   Ru: Getting started. I understand our webpage is interactive, and has no endpoint url. Though I now know how to navigate it using RSelenium, I haven't quite found the best way to find the elements in page using CSS selectors. I think this may be because we have a lot of classes within a div? and divs within divs? I feel this may be easier to understand once I understand selection of different elements so I'm still looking for tutorials on this.  

-   Maggie: Right now, I am trying to determine a better way of web
    scraping the website containing the names of doctors that works with
    the formatting of the website, because our current method is based
    mostly around the manual collection and input of data.

### What are you planning to do next week?

-   Rachel:

-   Ru: I'm planning to learning more about css selection in RSelenium and find out if I can pull out a few doctor's names and their addresses from the website using RSelenium and possibly rvest.  

-   Maggie: Do more research on Selenium and start working with it or a
    similar program to try to scrape the website for relevant data for
    our client.
